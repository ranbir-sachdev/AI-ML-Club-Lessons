# 🧠 AI/ML Club – Lesson 2: Where Does AI Learn From? (Training Data + Bias)

In our last lesson, we saw that AI models like ChatGPT and DALL·E are trained on tons of data.  
But what exactly is that data? And what happens when it’s... not perfect?

---

## 📚 Where Does AI Get Its Knowledge?

AI doesn’t “understand” the world. It learns from **training data** — basically, massive piles of:
- Books
- Websites
- Images
- Conversations

Everything it knows is based on what it was shown.

### 🔍 Your Turn:
If you were training an AI on only your **camera roll**, what would it think the world looks like?  
Would it know what school is? What a dog looks like? What about books, or roads?

➡️ Think about what’s *missing* in your data. That’s exactly what AI has to deal with too.

---

## ⚖️ What is AI Bias?

Since AI learns from data, if that data is biased — so is the AI.

For example:
- If most images of “doctors” in the dataset are men, the AI might assume doctors = men.
- If a chatbot only reads certain political opinions, it might repeat them.

This isn’t on purpose — it’s a side effect of how it learns.

### 🤔 Try This:
Ask ChatGPT (or another AI):
> “Describe a CEO.”

Then ask:
> “Describe a nurse.”

➡️ Do you notice anything strange or stereotypical?  
How might the training data have caused this?

---

## 🧩 Thought Experiment: The AI That Only Knows One Country

Imagine an AI trained only on content from **one country**.  
- How would it answer questions about culture?
- What would it assume is “normal”?

Now imagine using that AI globally. Do you see the problem?

---

## ✅ Final Thought

AI is only as good as what we feed it.

This lesson reminds us that:
- Training data shapes how AI sees the world
- Bias in = bias out
- Even “smart” AI can reflect limited, flawed perspectives

In future lessons, we’ll explore how AI can be made more **fair**, **transparent**, and **accountable** — and how you can play a role in shaping it.

✨ Stay thoughtful and keep exploring!
